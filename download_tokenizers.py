#!/usr/bin/env python
"""
ä¸‹è½½è®­ç»ƒæ‰€éœ€çš„ tokenizer æ–‡ä»¶

ä½¿ç”¨æ–¹æ³•:
    python download_tokenizers.py              # é»˜è®¤ä½¿ç”¨ hf-mirror.com é•œåƒ
    python download_tokenizers.py --no-mirror  # ä½¿ç”¨ HuggingFace å®˜æ–¹æº
    
æ‰‹åŠ¨ä¸‹è½½ï¼ˆå¦‚è„šæœ¬æ— æ³•ä½¿ç”¨ï¼‰:
    1. T5 Tokenizer (æ”¾åˆ° models/t5_tokenizer/):
       - https://huggingface.co/google/t5-v1_1-xxl/resolve/main/spiece.model
       - https://huggingface.co/google/t5-v1_1-xxl/resolve/main/tokenizer_config.json
       - https://huggingface.co/google/t5-v1_1-xxl/resolve/main/special_tokens_map.json
       
    2. Qwen3 Tokenizer (æ”¾åˆ° models/text_encoders/):
       - https://huggingface.co/Qwen/Qwen3-0.6B-Base/resolve/main/tokenizer.json
       - https://huggingface.co/Qwen/Qwen3-0.6B-Base/resolve/main/vocab.json
       - https://huggingface.co/Qwen/Qwen3-0.6B-Base/resolve/main/merges.txt
       - https://huggingface.co/Qwen/Qwen3-0.6B-Base/resolve/main/tokenizer_config.json
       - https://huggingface.co/Qwen/Qwen3-0.6B-Base/resolve/main/special_tokens_map.json
       
    3. Qwen3 æ¨¡å‹æƒé‡ (æ”¾åˆ° models/text_encoders/):
       - https://huggingface.co/Qwen/Qwen3-0.6B-Base/resolve/main/model.safetensors
       
    å›½å†…é•œåƒ: æŠŠ huggingface.co æ›¿æ¢ä¸º hf-mirror.com
"""
import os
import argparse
from pathlib import Path

def setup_mirror(use_mirror: bool = True):
    """è®¾ç½® HuggingFace é•œåƒ"""
    if use_mirror:
        os.environ.setdefault("HF_ENDPOINT", "https://hf-mirror.com")
        print("ä½¿ç”¨é•œåƒ: https://hf-mirror.com")
    else:
        print("ä½¿ç”¨å®˜æ–¹æº: https://huggingface.co")

def download_t5_tokenizer(output_dir: str):
    """ä¸‹è½½ T5-XXL tokenizer æ–‡ä»¶"""
    from huggingface_hub import hf_hub_download
    
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    repo_id = "google/t5-v1_1-xxl"
    files = [
        "spiece.model",
        "tokenizer_config.json",
        "special_tokens_map.json",
    ]
    
    print(f"\nğŸ“¥ ä¸‹è½½ T5 tokenizer åˆ° {output_dir}...")
    print(f"   æ¥æº: {repo_id}")
    for filename in files:
        try:
            path = hf_hub_download(
                repo_id=repo_id,
                filename=filename,
                local_dir=str(output_dir),
                local_dir_use_symlinks=False,
            )
            print(f"   âœ… {filename}")
        except Exception as e:
            print(f"   âŒ {filename}: {e}")


def download_qwen3_tokenizer(output_dir: str):
    """ä¸‹è½½ Qwen3 tokenizer æ–‡ä»¶"""
    from huggingface_hub import hf_hub_download
    
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    repo_id = "Qwen/Qwen3-0.6B-Base"
    files = [
        "tokenizer.json",
        "tokenizer_config.json",
        "special_tokens_map.json",
        "vocab.json",
        "merges.txt",
    ]
    
    print(f"\nğŸ“¥ ä¸‹è½½ Qwen3 tokenizer åˆ° {output_dir}...")
    print(f"   æ¥æº: {repo_id}")
    for filename in files:
        try:
            path = hf_hub_download(
                repo_id=repo_id,
                filename=filename,
                local_dir=str(output_dir),
                local_dir_use_symlinks=False,
            )
            print(f"   âœ… {filename}")
        except Exception as e:
            print(f"   âš ï¸  {filename}: è·³è¿‡ ({e})")


def main():
    parser = argparse.ArgumentParser(
        description="ä¸‹è½½è®­ç»ƒæ‰€éœ€çš„ tokenizer æ–‡ä»¶",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
æ‰‹åŠ¨ä¸‹è½½è¯´æ˜:
  å¦‚æœè„šæœ¬æ— æ³•ä½¿ç”¨ï¼Œå¯ä»¥æ‰‹åŠ¨ä»ä»¥ä¸‹åœ°å€ä¸‹è½½æ–‡ä»¶ï¼š
  
  T5 Tokenizer â†’ models/t5_tokenizer/
    https://huggingface.co/google/t5-v1_1-xxl
    
  Qwen3 Tokenizer â†’ models/text_encoders/  
    https://huggingface.co/Qwen/Qwen3-0.6B-Base
    
  å›½å†…ç”¨æˆ·: æŠŠ huggingface.co æ›¿æ¢ä¸º hf-mirror.com
""")
    parser.add_argument("--no-mirror", action="store_true", 
                        help="ä¸ä½¿ç”¨é•œåƒï¼Œç›´æ¥è®¿é—® HuggingFace å®˜æ–¹æº")
    parser.add_argument("--output", type=str, default="",
                        help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: ./modelsï¼‰")
    args = parser.parse_args()
    
    # è®¾ç½®é•œåƒ
    setup_mirror(use_mirror=not args.no_mirror)
    
    # ç¡®å®šè¾“å‡ºç›®å½•
    if args.output:
        base_dir = Path(args.output)
    else:
        base_dir = Path(__file__).parent / "models"
    
    print(f"\nğŸ“ æ¨¡å‹ç›®å½•: {base_dir.absolute()}")
    
    # 1. ä¸‹è½½ T5 tokenizer
    download_t5_tokenizer(base_dir / "t5_tokenizer")
    
    # 2. ä¸‹è½½ Qwen3 tokenizer
    download_qwen3_tokenizer(base_dir / "text_encoders")
    
    print("\n" + "="*50)
    print("âœ… Tokenizer ä¸‹è½½å®Œæˆï¼")
    print()
    print("âš ï¸  æ³¨æ„: è¿˜éœ€è¦æ‰‹åŠ¨ä¸‹è½½ä»¥ä¸‹å¤§æ–‡ä»¶:")
    print()
    print("  1. Anima ä¸»æ¨¡å‹ â†’ models/transformers/anima-preview.safetensors")
    print("     https://huggingface.co/circlestone-labs/Anima")
    print()
    print("  2. VAE â†’ models/vae/qwen_image_vae.safetensors")
    print("     https://huggingface.co/circlestone-labs/Anima")
    print()
    print("  3. Qwen3 æƒé‡ â†’ models/text_encoders/model.safetensors")
    print("     https://huggingface.co/Qwen/Qwen3-0.6B-Base")
    print()
    print("  å›½å†…é•œåƒ: æŠŠ huggingface.co æ›¿æ¢ä¸º hf-mirror.com")
    print("="*50)


if __name__ == "__main__":
    main()
